{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science in a Blaze - Part 1\n",
    "\n",
    "### Self education in Data Science\n",
    "\n",
    "Tying up my time at Mapillary in mid January, I decided that instead of diving directly back into a job hunt, that I would take a bit of time to hone existing skills and develop some new. Ever since extracting and visualizing sentiment data from New York Times comments as an undergraduate in design school, I've been attacted to data analysis as a means to gain and share a greater understanding of the world. With some time on my hands and a passion for writing software in Python, I decided to dive in heads first. This is a first this series of blog posts where I'll catalog my self-education and share some  of what I build.\n",
    "\n",
    "Thus far, my eduction has been self driven on [Kaggle](http://kaggle.com/) - there's a ton of knowledge there! While my experience diving into the domain has been pretty humbling -- pretty much everyone around me knows so much more, it's also been enlightening and energizing -- the possibilities are boundless.\n",
    "\n",
    "Thinking about next steps, my rough plans are to:\n",
    "- complete an end to end machine learning project and publish my progress on this blog and on Kaggle\n",
    "- complete fast.ai [Deep Learning Part 1](http://course.fast.ai/)\n",
    "- build a deep learning compute\n",
    "- compete in at least one Kaggle competetion, hopefully joining a team to boost my learning\n",
    "\n",
    "### Starting an E2E Project: Predicting the cause of Wildfires in the United States\n",
    "\n",
    "Surveying the datasets available to work with on Kaggle, I was immediately attracted to a dataset describing [1.88M US Wildfires](https://www.kaggle.com/rtatman/188-million-us-wildfires) over 15 years [originally published](https://www.fs.usda.gov/rds/archive/Product/RDS-2013-0009.4/) by the US Forest Service. Between a geospatial component, high topical relevance, and personal interest in the subject, I decided that I'd focus my first end to end project on predicting the cause of a Fire given information available when the fire began. Given the limited information available in the data set, it's highly likely that integrating additional data such as historical weather or land use, will be essential to building a strong model.\n",
    "\n",
    "This first blog post outlines covers the initial steps of preparing an environment and data to begin working with it. Since the project is still moving, I expect the content here to change - updates will be posted below:\n",
    "\n",
    "- *2017/1/30* - initial post\n",
    "\n",
    "### Some notes on Jupyter\n",
    "\n",
    "This post, and work, was completed in a Jupyter notebook running in a docker container. While my process has been roughly cataloged [here](https://www.andrewmahon.info/blog/docker-compose-data-science), throughout the project, the container has been modified a bit to update existing tools and provide new tools. I'll write a new blog post about it soon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Environment\n",
    "\n",
    "The first thing that we need to do is prepare our working environment\n",
    "\n",
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "import geopandas as gpd\n",
    "import graphviz\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import palettable\n",
    "import pandas as pd\n",
    "import pandas.tools.plotting as pdplot\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import shapely\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (15, 15)\n",
    "mpl.rcParams['agg.path.chunksize'] = 100000\n",
    "\n",
    "qual_colormap = palettable.matplotlib.Inferno_20\n",
    "quant_colormap = palettable.matplotlib.Inferno_20_r\n",
    "\n",
    "mpl.rcParams['image.cmap'] = qual_colormap.mpl_colormap\n",
    "sns.set(rc={'figure.figsize':(15, 15)})\n",
    "sns.set_palette(qual_colormap.mpl_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Define location of data file, open SQLite connection, define query, read into DF. Since we dont have a good sense of what's in the data, let's load all columnns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = '/data/188-million-us-wildfires/src/FPA_FOD_20170508.sqlite'\n",
    "conn = sqlite3.connect(input_filename)\n",
    "\n",
    "query = '''\n",
    "    SELECT\n",
    "        NWCG_REPORTING_AGENCY,\n",
    "        NWCG_REPORTING_UNIT_ID,\n",
    "        NWCG_REPORTING_UNIT_NAME,\n",
    "        FIRE_NAME,\n",
    "        COMPLEX_NAME,\n",
    "        FIRE_YEAR,\n",
    "        DISCOVERY_DATE,\n",
    "        DISCOVERY_DOY,\n",
    "        DISCOVERY_TIME,\n",
    "        STAT_CAUSE_CODE,\n",
    "        STAT_CAUSE_DESCR,\n",
    "        CONT_DATE,\n",
    "        CONT_DOY,\n",
    "        CONT_TIME,\n",
    "        FIRE_SIZE,\n",
    "        FIRE_SIZE_CLASS,\n",
    "        LATITUDE,\n",
    "        LONGITUDE,\n",
    "        OWNER_CODE,\n",
    "        OWNER_DESCR,\n",
    "        STATE,\n",
    "        COUNTY\n",
    "    FROM\n",
    "        Fires;\n",
    "'''\n",
    "\n",
    "raw_df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Raw Data\n",
    "\n",
    "Now that our data is loaded, let's give it a very high level look and start to develop an understanding of what we're working with.\n",
    "\n",
    "### Info\n",
    "Let's have a look at our column names and the type of data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "Let's see how many values are missing in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample\n",
    "Let's look at some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some initial observations about the data:\n",
    "- **STAT_CAUSE_CODE** and **STAT_CAUSE_DESCR** are related and represent the value that we are trying to predict. Before training, we'll drop **STAT_CAUSE_DESCR** in favor of the numerical value of **STAT_CAUSE_CODE**.\n",
    "- **OWNER_CODE** and **OWNER_DESCR** are related and describe the owner of the property where the fire was discovered. This is an interesting value because it represents the land management and usage of a particular peice of land. These will be interesting in our investigation. Before training, we'll drop **OWNER_DESCR** in favor of the numerical value of **OWNER_CODE**.\n",
    "- **DISCOVERY_DATE**, **DISCOVERY_DOY**, **DISCOVERY_TIME** describe the time that a fire was discovered. **DISCOVERY_DOY** is most interesting to our investigation due to it's relation to climate and usage patterns of a particular peice of land. **DISCOVERY_TIME** may be interesting due, but also might be too fine grained, additionally, it's missing values - let's drop it for now. **DISCOVERY_DATE** is [TKTK]\n",
    "- **LATITUDE**, and **LONGITUDE** are both very interesting due to their very high relationship to land cover, land use, and climate - all three big factors in wildfire creation.\n",
    "- **STATE** and  both categorically describe the location of a fire. **STATE** might be interesting due to it's relation in land use patterns. **STATE** also might prove to be a useful generalization of the more specific **LATITUDE**, and **LONGITUDE*.\n",
    "- **COUNTY**, while potentially interesting, has too many missing values. If we want to more closely explore categorial location data, we can add it via a geocoding process in the data engineering process.\n",
    "- A number of columns contain information about how a fire was addressed and not about what caused the fire. Lets' ignore the following columns for now: **NWCG_REPORTING_AGENCY**, **NWCG_REPORTING_UNIT_ID**, **NWCG_REPORTING_UNIT_NAME**, **FIRE_NAME**, **FIRE_COMPLEX**, **CONT_DATE**, **CONT_DOY**, **CONT_TIME**, **FIRE_SIZE**, **FIRE_SIZE_CLASS**\n",
    "\n",
    "This leaves us with the following interesting fields:\n",
    "- **STAT_CAUSE_CODE**\n",
    "- **STAT_CAUSE_DESCR** [for EDA]\n",
    "- **OWNER_CODE**\n",
    "- **OWNER_DESCR**\n",
    "- **DISCOVERY_DOY**\n",
    "- **LATITUDE**\n",
    "- **LONGITUDE**\n",
    "- **STATE**\n",
    "\n",
    "Some things we can keep in our back pocket for future exploration:\n",
    "- look harder at **DISCOVERY_TIME**\n",
    "- look harder at **DISCOVERY_DATE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Human Readable Mappings\n",
    "Before we drop our human readable columns, let's create a set of mappings that we can use to associate numberical categories back to human readable categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_cause_mapping = raw_df \\\n",
    "    .groupby(['STAT_CAUSE_DESCR', 'STAT_CAUSE_CODE']) \\\n",
    "    .size()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .drop(0, axis=1)\\\n",
    "    .set_index('STAT_CAUSE_CODE')\\\n",
    "    .sort_index()['STAT_CAUSE_DESCR']\n",
    "stat_cause_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner_code_mapping = raw_df \\\n",
    "    .groupby(['OWNER_DESCR', 'OWNER_CODE']) \\\n",
    "    .size()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .drop(0, axis=1)\\\n",
    "    .set_index('OWNER_CODE')\\\n",
    "    .sort_index()['OWNER_DESCR']\n",
    "owner_code_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip Data\n",
    "\n",
    "Let's create a new dataframe that contains only the fields that we're interested in. This will reduce memory usage and help keep things tidy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.copy()[[\n",
    "    'STAT_CAUSE_CODE',\n",
    "    'STAT_CAUSE_DESCR',\n",
    "    'OWNER_CODE',\n",
    "    'OWNER_DESCR',\n",
    "    'DISCOVERY_DOY',\n",
    "    'LATITUDE',\n",
    "    'LONGITUDE',\n",
    "    'STATE'\n",
    "]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint [0]\n",
    "\n",
    "Getting `gdf` to the state it is right now took some time. Let's checkpoint the file onto disk so we can come back to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_checkpoint_path = '../data/188-million-us-wildfires/wildfires-cause-prediction-df_checkpoint_0.pickle'\n",
    "\n",
    "# OVERWRITE = False\n",
    "\n",
    "# if not os.path.exists(df_checkpoint_path) or OVERWRITE:\n",
    "#     df.to_pickle(df_checkpoint_path)\n",
    "# else :\n",
    "#     df = pd.read_pickle(df_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "\n",
    "We need to split the data into a train set and a test set. The train set will be used to build our model, and the test set will be used to evaluate the model.\n",
    "\n",
    "We will use sklearn's [`model_selection.train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split our dataframe into two.\n",
    "\n",
    "Last, we will create a convienience `_df` that allows us to access the union of the test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = model_selection.train_test_split(df)\n",
    "\n",
    "display(HTML('''\n",
    "<p>\n",
    "    Number of Training Rows: {}<br />\n",
    "    Number of Test Rows: {}\n",
    "'''.format(train_df.shape[0], test_df.shape[0])))\n",
    "\n",
    "_df = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# END BLOG 1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog Post 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "\n",
    "### Quantify Data\n",
    "\n",
    "A couple fields in our reduced set are still non-numeric, in particular the **STATE** field is still text - let's convert this to a numeric value.\n",
    "\n",
    "Ref: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = sklearn.preprocessing.LabelEncoder()\n",
    "for dataframe in _df:\n",
    "    dataframe['STATE_CODE'] = label.fit_transform(dataframe['STATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin Data\n",
    "\n",
    "Ref: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html  https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data [0] - Exploratory Data Analysis\n",
    "\n",
    "1. Causes\n",
    "1. Week of Year [todo]\n",
    "1. Week of Year and Cause\n",
    "2. Owner\n",
    "3. Owner and Cause\n",
    "4. State\n",
    "5. State and Cause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causes\n",
    "\n",
    "Let's explore the causes of wildfires represented in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts_by_cause = test_df.groupby('STAT_CAUSE_DESCR')\\\n",
    "    .size()\\\n",
    "    .sort_values(ascending=False)\n",
    "counts_by_cause_pcts = counts_by_cause.apply(lambda x: 100 * x / float(counts_by_cause.sum()))\n",
    "\n",
    "ax = sns.barplot(counts_by_cause.index, counts_by_cause.values)\n",
    "ax.set_xticklabels(labels=counts_by_cause.index, rotation=90)\n",
    "\n",
    "for i, p in enumerate(ax.patches):\n",
    "    height = p.get_height()\n",
    "    width = p.get_width()\n",
    "    ax.text(\n",
    "        p.get_x()+(width/2.),\n",
    "        height + 1000,\n",
    "        '{:1.2f}%'.format(counts_by_cause_pcts[i]),\n",
    "        ha=\"center\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_by_doy = train_df.groupby('DISCOVERY_DOY').size()\n",
    "ax = count_by_doy.plot()\n",
    "ax.set_xlim(0,367)\n",
    "ax.set_ylim(0,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of Year and Cause\n",
    "\n",
    "Hypothesis: [TKTK]\n",
    "\n",
    "Process: Add 'DISCOVERY_WEEK' column to table. Note that we end up with 53 weeks as a result of Leap Years. I also added one to 1 index the list of weeks to better adhere with common understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process: Create a piviot table that relates `STAT_CAUSE_DESCR` to `DISCOVERY_WEEK`. Plot that using a seaborne heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cause_by_doy = train_df.groupby(['DISCOVERY_DOY', 'STAT_CAUSE_DESCR'])\\\n",
    "    .size()\\\n",
    "    .unstack()\n",
    "causes = list(cause_by_doy.columns.values)\n",
    "cause_by_doy['Total'] = cause_by_doy.sum(axis=1)\n",
    "cause_by_doy_proportional = pd.DataFrame()\n",
    "for cause in causes:\n",
    "    cause_by_doy_proportional[cause] = cause_by_doy[[cause, 'Total']].apply(lambda x: x[cause]/x['Total'], axis=1)\n",
    "cause_by_doy = cause_by_doy.drop('Total', axis=1)\n",
    "cause_by_doy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "ax = cause_by_doy.plot.area()\n",
    "ax.set_xlim(0,367)\n",
    "ax.set_ylim(0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(\n",
    "    cause_by_doy,\n",
    "    cbar_kws={'shrink':.9 },\n",
    "    annot=False,\n",
    "    cmap=quant_colormap.mpl_colormap\n",
    ")\n",
    "for i, label in enumerate(ax.yaxis.get_ticklabels()):\n",
    "    label.set_visible(False)\n",
    "    if i % 7 == 0:\n",
    "        label.set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(\n",
    "    cause_by_doy_proportional,\n",
    "    cbar_kws={'shrink':.9 }, \n",
    "    annot=False,\n",
    "    cmap=quant_colormap.mpl_colormap\n",
    ")\n",
    "for i, label in enumerate(ax.yaxis.get_ticklabels()):\n",
    "    label.set_visible(False)\n",
    "    if i % 7 == 0:\n",
    "        label.set_visible(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis: [TKTK]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts_by_owner = train_df.groupby('OWNER_DESCR')\\\n",
    "    .size()\\\n",
    "    .sort_values(ascending=False)\n",
    "\n",
    "ax = sns.barplot(counts_by_owner.index, counts_by_owner.values)\n",
    "labels = ax.set_xticklabels(labels=counts_by_owner.index, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cause and Owner\n",
    "\n",
    "Add 'DISCOVERY_WEEK' column to table. Note that we end up with 53 weeks as a result of Leap Years. I also added one to 1 index the list of weeks to better adhere with common understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_by_week = train_df.groupby(['OWNER_DESCR', 'STAT_CAUSE_DESCR'])\\\n",
    "    .size()\\\n",
    "    .unstack()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    cause_by_week,\n",
    "    cbar_kws={'shrink':.9 }, \n",
    "    annot=False,\n",
    "    cmap='inferno_r'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts_by_state = train_df.groupby('STATE')\\\n",
    "    .size()\\\n",
    "    .sort_values(ascending=False)\n",
    "\n",
    "ax = sns.barplot(counts_by_state.index, counts_by_state.values)\n",
    "labels = ax.set_xticklabels(labels=counts_by_state.index, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State, Geographic\n",
    "\n",
    "Load our State outlines, join in some abbreviations.\n",
    "\n",
    "Outlines sourced from: http://eric.clst.org/tech/usgeojson/\n",
    "\n",
    "#### Create States Dataframe containing Border Geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_outlines_path = '/data/188-million-us-wildfires/src/gz_2010_us_040_00_500k.json'\n",
    "state_outlines_df = gpd.read_file(state_outlines_path)\n",
    "\n",
    "state_codes_path = '/data/188-million-us-wildfires/src/state_codes.json'\n",
    "state_codes_df = pd.read_json(state_codes_path, orient='records').set_index('name')\n",
    "states = state_outlines_df\\\n",
    "    .join(state_codes_df, on='NAME').set_index('alpha-2')\\\n",
    "    .join(counts_by_state.to_frame().rename(columns={0:'count'}))\n",
    "states.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states.to_crs({'init': 'epsg:3395'}).plot(column='count', cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and Cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_by_state = train_df.groupby(['STATE', 'STAT_CAUSE_DESCR'])\\\n",
    "    .size()\\\n",
    "    .unstack()\n",
    "causes = list(cause_by_state.columns.values)\n",
    "cause_by_state['Total'] = cause_by_state.sum(axis=1)\n",
    "cause_by_state_proportional = pd.DataFrame()\n",
    "for cause in causes:\n",
    "    cause_by_state_proportional[cause] = cause_by_state[[cause, 'Total']].apply(lambda x: x[cause]/x['Total'], axis=1)\n",
    "cause_by_state = cause_by_state.drop('Total', axis=1)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    cause_by_state,\n",
    "    cbar_kws={'shrink':.9 }, \n",
    "    annot=False,\n",
    "    cmap='inferno_r'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Coorelation\n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heatmap of dataset\n",
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    #colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    colormap = quant_colormap.mpl_colormap\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        square=True,\n",
    "        cmap = colormap,\n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,\n",
    "        vmax=1.0,\n",
    "        linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# END BLOG 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENGINEER LOCATION OBJECT\n",
    "\n",
    "# geometry = [shapely.geometry.Point(xy) for xy in zip(df.LONGITUDE, df.LATITUDE)]\n",
    "# df.drop(['LONGITUDE', 'LATITUDE'], axis=1, inplace=True)\n",
    "# crs = {'init': 'epsg:4269'}\n",
    "# gdf = gpd.GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "# del df\n",
    "# gdf = gdf.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "# print(gdf.info())\n",
    "# gdf.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovery Week of Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in _df:\n",
    "    dataframe['DISCOVERY_WEEK'] = dataframe['DISCOVERY_DOY']\\\n",
    "        .apply(lambda x: math.floor(x/7) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Regions\n",
    "\n",
    "\n",
    "\n",
    "Ref: https://www.ncdc.noaa.gov/monitoring-references/maps/us-climate-regions.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLIMATE REGION\n",
    "climate_regions = {\n",
    "    \"northwest\": [\n",
    "        \"WA\",\n",
    "        \"OR\",\n",
    "        \"ID\"\n",
    "    ],\n",
    "    \"west\": [\n",
    "        \"CA\",\n",
    "        \"NV\",\n",
    "    ],\n",
    "    \"southwest\": [\n",
    "        \"UT\",\n",
    "        \"CO\",\n",
    "        \"AZ\",\n",
    "        \"NM\",\n",
    "    ],\n",
    "    \"northern_rockies\": [\n",
    "        \"MT\",\n",
    "        \"ND\",\n",
    "        \"SD\",\n",
    "        \"WY\",\n",
    "        \"NE\",\n",
    "    ],\n",
    "    \"upper_midwest\": [\n",
    "        \"KS\",\n",
    "        \"OK\",\n",
    "        \"TX\",\n",
    "        \"AR\",\n",
    "        \"LA\",\n",
    "        \"MS\",\n",
    "    ],\n",
    "    \"south\": [\n",
    "        \"MN\",\n",
    "        \"WI\",\n",
    "        \"MI\",\n",
    "        \"IA\"\n",
    "    ],\n",
    "    \"ohio_valley\": [\n",
    "        \"MO\",\n",
    "        \"IL\",\n",
    "        \"IN\",\n",
    "        \"OH\",\n",
    "        \"WV\",\n",
    "        \"KY\",\n",
    "        \"TN\",\n",
    "    ],\n",
    "    \"southeast\": [\n",
    "        \"VA\",\n",
    "        \"NC\",\n",
    "        \"SC\",\n",
    "        \"GA\",\n",
    "        \"AL\",\n",
    "        \"FL\",\n",
    "    ],\n",
    "    \"northeast\": [\n",
    "        \"ME\",\n",
    "        \"NH\",\n",
    "        \"VT\",\n",
    "        \"NY\",\n",
    "        \"PA\",\n",
    "        \"MA\",\n",
    "        \"RI\",\n",
    "        \"CT\",\n",
    "        \"NJ\",\n",
    "        \"DE\",\n",
    "        \"MD\",\n",
    "        \"DC\"\n",
    "    ],\n",
    "    \"alaska\": [\n",
    "        \"AK\",\n",
    "    ],\n",
    "    \"hawaii\": [\n",
    "        \"HI\"\n",
    "    ],\n",
    "    \"puerto_rico\": [\n",
    "        \"PR\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "state_region_mapping = {}\n",
    "for region, region_states in climate_regions.items():\n",
    "    for state in region_states:\n",
    "        state_region_mapping[state] = region\n",
    "        \n",
    "for dataframe in _df:\n",
    "    dataframe['CLIMATE_REGION'] = dataframe['STATE']\\\n",
    "        .apply(lambda x: state_region_mapping[x])\n",
    "        \n",
    "label = sklearn.preprocessing.LabelEncoder()\n",
    "for dataframe in _df:\n",
    "    dataframe['CLIMATE_REGION_CODE'] = label.fit_transform(dataframe['CLIMATE_REGION'])\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash\n",
    "\n",
    "def geohashes_for_geometry(geometry, precision=[7, 6, 4, 3]):\n",
    "    _lon = geometry.coords.xy[0][0]\n",
    "    _lat = geometry.coords.xy[1][0]\n",
    "    _geohash = geohash.encode(_lat, _lon, precision=precision[0])\n",
    "    _output = [_geohash[0:p] for p in precision]\n",
    "    return pd.Series(_output)\n",
    "\n",
    "\n",
    "for dataframe in _df:\n",
    "    geohashes = ['geometry'].apply(geohashes_for_geometry, precision=[4])\n",
    "geohashes = geohashes.rename(columns={0: 'geohash_5'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H3 Binning\n",
    "\n",
    "Ref:\n",
    "\n",
    "https://github.com/uber/h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h3ToGeoBoundary: error while loading shared libraries: libh3.1.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "h3ToGeoBoundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data [1]\n",
    "\n",
    "Now that we have engineered some new data, let's revisit some of our exploratory techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_by_region = train_df.groupby(['CLIMATE_REGION', 'STAT_CAUSE_DESCR'])\\\n",
    "    .size()\\\n",
    "    .unstack()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    cause_by_region,\n",
    "    cbar_kws={'shrink':.9 }, \n",
    "    annot=False,\n",
    "    cmap='inferno_r'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Coorelation\n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heatmap of dataset\n",
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    #colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    colormap = quant_colormap.mpl_colormap\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        square=True,\n",
    "        cmap = colormap,\n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,\n",
    "        vmax=1.0,\n",
    "        linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop text category fields that duplicate numerical category fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train_df = train_df.drop([\n",
    "#     'STAT_CAUSE_DESCR',\n",
    "#     'OWNER_DESCR',\n",
    "#     'STATE',\n",
    "#     'CLIMATE_REGION',\n",
    "# ], axis=1)\n",
    "# clean_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Helper\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion Matrix',\n",
    "                          cmap=quant_colormap.mpl_colormap):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(shrink=0.65)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh =  cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Actual label')\n",
    "    plt.ylabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Benchmark\n",
    "\n",
    "Before we train a model, let's establish a benchmark to work against. To do this, we will develop by hand, a very simple decision tree.\n",
    "\n",
    "The simplest benchmark that we can set is with a model that always evaluates to a single response. Our benchmark model will evaluate to `5.0`, the code representative of 'Debris Burning'.\n",
    "\n",
    "TODO: this benchmark should be improved once we have engineered some new data into our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_fields = [\n",
    "    'OWNER_CODE',\n",
    "    'DISCOVERY_WEEK',\n",
    "    'STATE_CODE'\n",
    "]\n",
    "\n",
    "target_fields = [\n",
    "    'STAT_CAUSE_CODE'\n",
    "]\n",
    "\n",
    "def benchmark_model(df):\n",
    "    return pd.DataFrame(data = {'STAT_CAUSE_CODE_PREDICT':[5.0 for i in range(0, df.shape[0])]})\n",
    "\n",
    "prediction = benchmark_model(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of our benchmark model. It should fall right around 23% - this is the rough proportion of fires caused by 'Debris Burning'.\n",
    "\n",
    "Ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score  http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    ")\n",
    "\n",
    "print('Accuracy: {} \\n\\n'.format(accuracy))\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    "))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df[target_fields], prediction)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    stat_cause_mapping.values,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD) Classifier\n",
    "\n",
    "[TKTK]\n",
    "\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier\n",
    "\n",
    "http://scikit-learn.org/stable/modules/sgd.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "source_fields = [\n",
    "    'OWNER_CODE',\n",
    "    'DISCOVERY_WEEK',\n",
    "    'STATE_CODE'\n",
    "]\n",
    "\n",
    "target_fields = [\n",
    "    'STAT_CAUSE_CODE'\n",
    "]\n",
    "\n",
    "classifier = SGDClassifier(\n",
    "    loss=\"hinge\",\n",
    "    penalty=\"l2\",\n",
    "    max_iter=5,\n",
    "    tol=None,\n",
    ")\n",
    "\n",
    "classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields]['STAT_CAUSE_CODE']\n",
    ")\n",
    "\n",
    "prediction = classifier.predict(\n",
    "    test_df[source_fields]\n",
    ")\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    ")\n",
    "\n",
    "print('Accuracy: {} \\n\\n'.format(accuracy))\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    "))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df[target_fields], prediction)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    stat_cause_mapping.values,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix'\n",
    ")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "source_fields = [\n",
    "    'OWNER_CODE',\n",
    "    'DISCOVERY_WEEK',\n",
    "    'STATE_CODE'\n",
    "]\n",
    "\n",
    "target_fields = [\n",
    "    'STAT_CAUSE_CODE'\n",
    "]\n",
    "\n",
    "classifier = DecisionTreeClassifier(\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields]\n",
    ")\n",
    "\n",
    "prediction = classifier.predict(\n",
    "    test_df[source_fields]\n",
    ")\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    ")\n",
    "\n",
    "print('Accuracy: {} \\n\\n'.format(accuracy))\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    "))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df[target_fields], prediction)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    stat_cause_mapping.values,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix'\n",
    ")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier Redux\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_fields = [\n",
    "    'OWNER_CODE',\n",
    "#     'DISCOVERY_WEEK',\n",
    "    'STATE_CODE'\n",
    "]\n",
    "\n",
    "target_fields = [\n",
    "    'STAT_CAUSE_CODE'\n",
    "]\n",
    "\n",
    "cv_split = sklearn.model_selection.ShuffleSplit(\n",
    "    n_splits=10,\n",
    "    test_size=0.3,\n",
    "    train_size=0.6,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_classifier = DecisionTreeClassifier(\n",
    "    class_weight=None,\n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    presort=False,\n",
    "    random_state=0,\n",
    "    splitter='best'\n",
    ")\n",
    "\n",
    "base_results = model_selection.cross_validate(\n",
    "    base_classifier,\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields],\n",
    "    cv = cv_split\n",
    ")\n",
    "\n",
    "base_classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n"
     ]
    }
   ],
   "source": [
    "print(base_classifier.tree_.node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 10,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'presort': False,\n",
      " 'random_state': 0,\n",
      " 'splitter': 'best'}\n",
      "Base Score: 0.4330733505867338\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(base_classifier.get_params())\n",
    "print(\"Base Score: {}\".format(base_results['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Error: remove_overlap: Graphviz not built with triangulation library\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['sfdp', '-Tsvg']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data, quiet)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mstderr_write_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['sfdp', '-Tsvg']' returned non-zero exit status 1."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x7fcfb2d46080>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = sklearn.tree.export_graphviz(\n",
    "    base_classifier,\n",
    "    out_file=None, \n",
    "    feature_names=source_fields,\n",
    "    class_names=True,\n",
    "    filled=True,\n",
    "    rounded = True\n",
    ")\n",
    "print(dot_data)\n",
    "graph = graphviz.Source(dot_data, engine='sfdp') \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Setup hyperparameter grid for decision tree. Using GridSearchCV, we will try various combinations of the parameters that we define.\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=0, test_size=0.3, train_size=0.6),\n",
       "       error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'splitter': ['best'], 'max_depth': [17, 19, 20, 22, 25], 'min_samples_split': [20, 40, 60], 'min_samples_leaf': [1, 2, 4, 8], 'min_weight_fraction_leaf': [0], 'max_features': [None], 'random_state': [0], 'max_leaf_nodes': [None], 'min_impurity_decrease': [0.0], 'class_weight': [None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"splitter\": [\"best\"],\n",
    "    \"max_depth\": [17, 19, 20, 22, 25],\n",
    "    \"min_samples_split\": [20, 40, 60],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],\n",
    "    \"min_weight_fraction_leaf\": [0],\n",
    "    \"max_features\": [None],\n",
    "    \"random_state\": [0],\n",
    "    \"max_leaf_nodes\": [None],\n",
    "    \"min_impurity_decrease\": [0.],\n",
    "    \"class_weight\": [None]\n",
    "}\n",
    "\n",
    "tuned_classifier = sklearn.model_selection.GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    hyperparameter_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=cv_split\n",
    ")\n",
    "\n",
    "tuned_classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': 19,\n",
      " 'max_features': None,\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 20,\n",
      " 'min_weight_fraction_leaf': 0,\n",
      " 'random_state': 0,\n",
      " 'splitter': 'best'}\n",
      "Tuned Score: 0.45072121577386226\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 3 and input n_features is 2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-60d97d3acc95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m tuned_prediction = classifier.predict(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_fields\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \"\"\"\n\u001b[1;32m    411\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    382\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 3 and input n_features is 2 "
     ]
    }
   ],
   "source": [
    "pprint.pprint(tuned_classifier.best_params_)\n",
    "print(\"Tuned Score: {}\".format(tuned_classifier.cv_results_['mean_test_score'][tuned_classifier.best_index_]))\n",
    "\n",
    "\n",
    "tuned_prediction = classifier.predict(\n",
    "    test_df[source_fields]\n",
    ")\n",
    "\n",
    "tuned_accuracy = sklearn.metrics.accuracy_score(\n",
    "    test_df[target_fields],\n",
    "    tuned_prediction\n",
    ")\n",
    "\n",
    "print('Accuracy: {} \\n\\n'.format(tuned_accuracy))\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    test_df[target_fields],\n",
    "    tuned_prediction\n",
    "))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df[target_fields], tuned_prediction)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    stat_cause_mapping.values,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix'\n",
    ")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Elimination\n",
    "\n",
    "[TKTK]\n",
    "\n",
    "Ref:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_classifier = sklearn.feature_selection.RFECV(\n",
    "    base_classifier,\n",
    "    step=1,\n",
    "    scoring='accuracy',\n",
    "    cv=cv_split\n",
    ")\n",
    "\n",
    "rfe_classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields]\n",
    ")\n",
    "\n",
    "rfe_support_columns = train_df[source_fields].columns.values[rfe_classifier.get_support()]\n",
    "\n",
    "rfe_results = model_selection.cross_validation(\n",
    "    base_classifier,\n",
    "    train_df[rfe_support_columns],\n",
    "    train_df[target_fields],\n",
    "    cv=cv_split\n",
    ")\n",
    "\n",
    "print(rfe_results)\n",
    "\n",
    "rfe_tuned_classifier = sklearn.model_selection.GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    hyperparameter_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=cv_split\n",
    ")\n",
    "\n",
    "rfe_tuned_classifier.fit(\n",
    "    train_df[rfe_support_columns],\n",
    "    train_df[target_fields]\n",
    ")\n",
    "\n",
    "print(\"RFE + Tuned Score: {}\".format(rfe_tuned_classifier.cv_results_['mean_test_score'][classifier.best_index_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
