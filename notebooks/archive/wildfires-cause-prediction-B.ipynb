{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science in a Blaze - Part 1\n",
    "\n",
    "### Self education in Data Science\n",
    "\n",
    "Tying up my time at Mapillary in mid January, I decided that instead of diving directly back into a job hunt, that I would take a bit of time to hone existing skills and develop some new. Ever since extracting and visualizing sentiment data from New York Times comments as an undergraduate in design school, I've been attacted to data analysis as a means to gain and share a greater understanding of the world. With some time on my hands and a passion for writing software in Python, I decided to dive in heads first. This is a first this series of blog posts where I'll catalog my self-education and share some  of what I build.\n",
    "\n",
    "Thus far, my eduction has been self driven on [Kaggle](http://kaggle.com/) - there's a ton of knowledge there! While my experience diving into the domain has been pretty humbling -- pretty much everyone around me knows so much more, it's also been enlightening and energizing -- the possibilities are boundless.\n",
    "\n",
    "Thinking about next steps, my rough plans are to:\n",
    "- complete an end to end machine learning project and publish my progress on this blog and on Kaggle\n",
    "- complete fast.ai [Deep Learning Part 1](http://course.fast.ai/)\n",
    "- build a deep learning compute\n",
    "- compete in at least one Kaggle competetion, hopefully joining a team to boost my learning\n",
    "\n",
    "### Starting an E2E Project: Predicting the cause of Wildfires in the United States\n",
    "\n",
    "Surveying the datasets available to work with on Kaggle, I was immediately attracted to a dataset describing [1.88M US Wildfires](https://www.kaggle.com/rtatman/188-million-us-wildfires) over 15 years [originally published](https://www.fs.usda.gov/rds/archive/Product/RDS-2013-0009.4/) by the US Forest Service. Between a geospatial component, high topical relevance, and personal interest in the subject, I decided that I'd focus my first end to end project on predicting the cause of a Fire given information available when the fire began. Given the limited information available in the data set, it's highly likely that integrating additional data such as historical weather or land use, will be essential to building a strong model.\n",
    "\n",
    "This first blog post outlines covers the initial steps of preparing an environment and data to begin working with it. Since the project is still moving, I expect the content here to change - updates will be posted below:\n",
    "\n",
    "- *2017/1/30* - initial post\n",
    "\n",
    "### Some notes on Jupyter\n",
    "\n",
    "This post, and work, was completed in a Jupyter notebook running in a docker container. While my process has been roughly cataloged [here](https://www.andrewmahon.info/blog/docker-compose-data-science), throughout the project, the container has been modified a bit to update too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Environment\n",
    "\n",
    "The first thing that we need to do is prepare our working environment\n",
    "\n",
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import os\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "import geopandas as gpd\n",
    "import graphviz\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import palettable\n",
    "import pandas as pd\n",
    "import pandas.tools.plotting as pdplot\n",
    "import pprint\n",
    "import seaborn as sns\n",
    "import shapely\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (15, 15)\n",
    "mpl.rcParams['agg.path.chunksize'] = 100000\n",
    "\n",
    "qual_colormap = palettable.matplotlib.Inferno_20\n",
    "quant_colormap = palettable.matplotlib.Inferno_20_r\n",
    "\n",
    "mpl.rcParams['image.cmap'] = qual_colormap.mpl_colormap\n",
    "sns.set(rc={'figure.figsize':(15, 15)})\n",
    "sns.set_palette(qual_colormap.mpl_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "Define location of data file, open SQLite connection, define query, read into DF. Since we dont have a good sense of what's in the data, let's load all columnns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = '/data/188-million-us-wildfires/src/FPA_FOD_20170508.sqlite'\n",
    "conn = sqlite3.connect(input_filename)\n",
    "\n",
    "query = '''\n",
    "    SELECT\n",
    "        NWCG_REPORTING_AGENCY,\n",
    "        NWCG_REPORTING_UNIT_ID,\n",
    "        NWCG_REPORTING_UNIT_NAME,\n",
    "        FIRE_NAME,\n",
    "        COMPLEX_NAME,\n",
    "        FIRE_YEAR,\n",
    "        DISCOVERY_DATE,\n",
    "        DISCOVERY_DOY,\n",
    "        DISCOVERY_TIME,\n",
    "        STAT_CAUSE_CODE,\n",
    "        STAT_CAUSE_DESCR,\n",
    "        CONT_DATE,\n",
    "        CONT_DOY,\n",
    "        CONT_TIME,\n",
    "        FIRE_SIZE,\n",
    "        FIRE_SIZE_CLASS,\n",
    "        LATITUDE,\n",
    "        LONGITUDE,\n",
    "        OWNER_CODE,\n",
    "        OWNER_DESCR,\n",
    "        STATE,\n",
    "        COUNTY\n",
    "    FROM\n",
    "        Fires;\n",
    "'''\n",
    "\n",
    "raw_df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Raw Data\n",
    "\n",
    "Now that our data is loaded, let's give it a very high level look and start to develop an understanding of what we're working with.\n",
    "\n",
    "### Info\n",
    "Let's have a look at our column names and the type of data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1880465 entries, 0 to 1880464\n",
      "Data columns (total 22 columns):\n",
      "NWCG_REPORTING_AGENCY       object\n",
      "NWCG_REPORTING_UNIT_ID      object\n",
      "NWCG_REPORTING_UNIT_NAME    object\n",
      "FIRE_NAME                   object\n",
      "COMPLEX_NAME                object\n",
      "FIRE_YEAR                   int64\n",
      "DISCOVERY_DATE              float64\n",
      "DISCOVERY_DOY               int64\n",
      "DISCOVERY_TIME              object\n",
      "STAT_CAUSE_CODE             float64\n",
      "STAT_CAUSE_DESCR            object\n",
      "CONT_DATE                   float64\n",
      "CONT_DOY                    float64\n",
      "CONT_TIME                   object\n",
      "FIRE_SIZE                   float64\n",
      "FIRE_SIZE_CLASS             object\n",
      "LATITUDE                    float64\n",
      "LONGITUDE                   float64\n",
      "OWNER_CODE                  float64\n",
      "OWNER_DESCR                 object\n",
      "STATE                       object\n",
      "COUNTY                      object\n",
      "dtypes: float64(8), int64(2), object(12)\n",
      "memory usage: 315.6+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "Let's see how many values are missing in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NWCG_REPORTING_AGENCY             0\n",
       "NWCG_REPORTING_UNIT_ID            0\n",
       "NWCG_REPORTING_UNIT_NAME          0\n",
       "FIRE_NAME                    957189\n",
       "COMPLEX_NAME                1875282\n",
       "FIRE_YEAR                         0\n",
       "DISCOVERY_DATE                    0\n",
       "DISCOVERY_DOY                     0\n",
       "DISCOVERY_TIME               882638\n",
       "STAT_CAUSE_CODE                   0\n",
       "STAT_CAUSE_DESCR                  0\n",
       "CONT_DATE                    891531\n",
       "CONT_DOY                     891531\n",
       "CONT_TIME                    972173\n",
       "FIRE_SIZE                         0\n",
       "FIRE_SIZE_CLASS                   0\n",
       "LATITUDE                          0\n",
       "LONGITUDE                         0\n",
       "OWNER_CODE                        0\n",
       "OWNER_DESCR                       0\n",
       "STATE                             0\n",
       "COUNTY                       678148\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample\n",
    "Let's look at some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NWCG_REPORTING_AGENCY</th>\n",
       "      <th>NWCG_REPORTING_UNIT_ID</th>\n",
       "      <th>NWCG_REPORTING_UNIT_NAME</th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>COMPLEX_NAME</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "      <th>...</th>\n",
       "      <th>CONT_DOY</th>\n",
       "      <th>CONT_TIME</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>OWNER_CODE</th>\n",
       "      <th>OWNER_DESCR</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1526538</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USTXHAS</td>\n",
       "      <td>Texas Forest Service - Henderson Area</td>\n",
       "      <td>HENDERSON - 423</td>\n",
       "      <td>None</td>\n",
       "      <td>2011</td>\n",
       "      <td>2455797.5</td>\n",
       "      <td>236</td>\n",
       "      <td>1406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>236.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>1.00</td>\n",
       "      <td>B</td>\n",
       "      <td>31.726667</td>\n",
       "      <td>-94.355000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>STATE OR PRIVATE</td>\n",
       "      <td>TX</td>\n",
       "      <td>Shelby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316255</th>\n",
       "      <td>BLM</td>\n",
       "      <td>USCACDD</td>\n",
       "      <td>California Desert District</td>\n",
       "      <td>BORDER 58</td>\n",
       "      <td>None</td>\n",
       "      <td>2005</td>\n",
       "      <td>2453732.5</td>\n",
       "      <td>362</td>\n",
       "      <td>2255</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>362.0</td>\n",
       "      <td>2312</td>\n",
       "      <td>0.10</td>\n",
       "      <td>A</td>\n",
       "      <td>32.577661</td>\n",
       "      <td>-116.627750</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779172</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USNYNYX</td>\n",
       "      <td>Fire Department of New York</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2014</td>\n",
       "      <td>2456742.5</td>\n",
       "      <td>85</td>\n",
       "      <td>1909</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.10</td>\n",
       "      <td>A</td>\n",
       "      <td>41.386700</td>\n",
       "      <td>-73.873500</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>NY</td>\n",
       "      <td>PUTNAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795654</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USWIWIS</td>\n",
       "      <td>Wisconsin Department of Natural Resources</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1992</td>\n",
       "      <td>2448729.5</td>\n",
       "      <td>108</td>\n",
       "      <td>2140</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2215</td>\n",
       "      <td>0.90</td>\n",
       "      <td>B</td>\n",
       "      <td>43.998542</td>\n",
       "      <td>-90.615036</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>WI</td>\n",
       "      <td>Monroe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268659</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USKYKYS</td>\n",
       "      <td>Kentucky Division of Forestry</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2008</td>\n",
       "      <td>2454504.5</td>\n",
       "      <td>39</td>\n",
       "      <td>1545</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1545</td>\n",
       "      <td>30.00</td>\n",
       "      <td>C</td>\n",
       "      <td>37.561090</td>\n",
       "      <td>-82.235660</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>KY</td>\n",
       "      <td>Pike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793850</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USWIWIS</td>\n",
       "      <td>Wisconsin Department of Natural Resources</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1995</td>\n",
       "      <td>2449836.5</td>\n",
       "      <td>119</td>\n",
       "      <td>1331</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1444</td>\n",
       "      <td>2.75</td>\n",
       "      <td>B</td>\n",
       "      <td>44.744363</td>\n",
       "      <td>-89.764700</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>WI</td>\n",
       "      <td>Marathon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397854</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USGAGAS</td>\n",
       "      <td>Georgia Forestry Commission</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1996</td>\n",
       "      <td>2450124.5</td>\n",
       "      <td>42</td>\n",
       "      <td>2240</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2310</td>\n",
       "      <td>0.80</td>\n",
       "      <td>B</td>\n",
       "      <td>32.012600</td>\n",
       "      <td>-83.042700</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>GA</td>\n",
       "      <td>Telfair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493028</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USMNMNS</td>\n",
       "      <td>Minnesota Department of Natural Resources</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2007</td>\n",
       "      <td>2454221.5</td>\n",
       "      <td>121</td>\n",
       "      <td>None</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A</td>\n",
       "      <td>45.854778</td>\n",
       "      <td>-93.919926</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>MN</td>\n",
       "      <td>Morrison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113349</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USCANEU</td>\n",
       "      <td>Nevada-Yuba-Placer Unit</td>\n",
       "      <td>FAR WEST 2</td>\n",
       "      <td>None</td>\n",
       "      <td>2001</td>\n",
       "      <td>2452126.5</td>\n",
       "      <td>217</td>\n",
       "      <td>None</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.10</td>\n",
       "      <td>A</td>\n",
       "      <td>39.051111</td>\n",
       "      <td>-121.313056</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>CA</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725060</th>\n",
       "      <td>FS</td>\n",
       "      <td>USIDBOF</td>\n",
       "      <td>Boise National Forest</td>\n",
       "      <td>LUCKY</td>\n",
       "      <td>None</td>\n",
       "      <td>2014</td>\n",
       "      <td>2456846.5</td>\n",
       "      <td>189</td>\n",
       "      <td>0006</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>2.00</td>\n",
       "      <td>B</td>\n",
       "      <td>43.591389</td>\n",
       "      <td>-115.999722</td>\n",
       "      <td>13.0</td>\n",
       "      <td>STATE OR PRIVATE</td>\n",
       "      <td>ID</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        NWCG_REPORTING_AGENCY NWCG_REPORTING_UNIT_ID  \\\n",
       "1526538                ST/C&L                USTXHAS   \n",
       "316255                    BLM                USCACDD   \n",
       "1779172                ST/C&L                USNYNYX   \n",
       "795654                 ST/C&L                USWIWIS   \n",
       "1268659                ST/C&L                USKYKYS   \n",
       "793850                 ST/C&L                USWIWIS   \n",
       "1397854                ST/C&L                USGAGAS   \n",
       "493028                 ST/C&L                USMNMNS   \n",
       "1113349                ST/C&L                USCANEU   \n",
       "1725060                    FS                USIDBOF   \n",
       "\n",
       "                          NWCG_REPORTING_UNIT_NAME                  FIRE_NAME  \\\n",
       "1526538      Texas Forest Service - Henderson Area            HENDERSON - 423   \n",
       "316255                  California Desert District                  BORDER 58   \n",
       "1779172                Fire Department of New York                       None   \n",
       "795654   Wisconsin Department of Natural Resources                       None   \n",
       "1268659              Kentucky Division of Forestry                       None   \n",
       "793850   Wisconsin Department of Natural Resources                       None   \n",
       "1397854                Georgia Forestry Commission                       None   \n",
       "493028   Minnesota Department of Natural Resources                       None   \n",
       "1113349                    Nevada-Yuba-Placer Unit  FAR WEST 2                  \n",
       "1725060                      Boise National Forest                      LUCKY   \n",
       "\n",
       "        COMPLEX_NAME  FIRE_YEAR  DISCOVERY_DATE  DISCOVERY_DOY DISCOVERY_TIME  \\\n",
       "1526538         None       2011       2455797.5            236           1406   \n",
       "316255          None       2005       2453732.5            362           2255   \n",
       "1779172         None       2014       2456742.5             85           1909   \n",
       "795654          None       1992       2448729.5            108           2140   \n",
       "1268659         None       2008       2454504.5             39           1545   \n",
       "793850          None       1995       2449836.5            119           1331   \n",
       "1397854         None       1996       2450124.5             42           2240   \n",
       "493028          None       2007       2454221.5            121           None   \n",
       "1113349         None       2001       2452126.5            217           None   \n",
       "1725060         None       2014       2456846.5            189           0006   \n",
       "\n",
       "         STAT_CAUSE_CODE          ...          CONT_DOY  CONT_TIME  FIRE_SIZE  \\\n",
       "1526538              1.0          ...             236.0       1800       1.00   \n",
       "316255               2.0          ...             362.0       2312       0.10   \n",
       "1779172              9.0          ...             180.0       1941       0.10   \n",
       "795654               2.0          ...             108.0       2215       0.90   \n",
       "1268659              5.0          ...              39.0       1545      30.00   \n",
       "793850               4.0          ...             119.0       1444       2.75   \n",
       "1397854              7.0          ...              42.0       2310       0.80   \n",
       "493028               9.0          ...               NaN       None       0.25   \n",
       "1113349              2.0          ...               NaN       None       0.10   \n",
       "1725060              3.0          ...             189.0       1154       2.00   \n",
       "\n",
       "        FIRE_SIZE_CLASS   LATITUDE   LONGITUDE  OWNER_CODE  \\\n",
       "1526538               B  31.726667  -94.355000        13.0   \n",
       "316255                A  32.577661 -116.627750         8.0   \n",
       "1779172               A  41.386700  -73.873500        14.0   \n",
       "795654                B  43.998542  -90.615036        14.0   \n",
       "1268659               C  37.561090  -82.235660        14.0   \n",
       "793850                B  44.744363  -89.764700        14.0   \n",
       "1397854               B  32.012600  -83.042700         8.0   \n",
       "493028                A  45.854778  -93.919926        14.0   \n",
       "1113349               A  39.051111 -121.313056        14.0   \n",
       "1725060               B  43.591389 -115.999722        13.0   \n",
       "\n",
       "                   OWNER_DESCR  STATE                COUNTY  \n",
       "1526538       STATE OR PRIVATE     TX                Shelby  \n",
       "316255                 PRIVATE     CA             San Diego  \n",
       "1779172  MISSING/NOT SPECIFIED     NY                PUTNAM  \n",
       "795654   MISSING/NOT SPECIFIED     WI                Monroe  \n",
       "1268659  MISSING/NOT SPECIFIED     KY                  Pike  \n",
       "793850   MISSING/NOT SPECIFIED     WI              Marathon  \n",
       "1397854                PRIVATE     GA  Telfair               \n",
       "493028   MISSING/NOT SPECIFIED     MN              Morrison  \n",
       "1113349  MISSING/NOT SPECIFIED     CA                  None  \n",
       "1725060       STATE OR PRIVATE     ID                   Ada  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NWCG_REPORTING_AGENCY</th>\n",
       "      <th>NWCG_REPORTING_UNIT_ID</th>\n",
       "      <th>NWCG_REPORTING_UNIT_NAME</th>\n",
       "      <th>FIRE_NAME</th>\n",
       "      <th>COMPLEX_NAME</th>\n",
       "      <th>FIRE_YEAR</th>\n",
       "      <th>DISCOVERY_DATE</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>DISCOVERY_TIME</th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "      <th>...</th>\n",
       "      <th>CONT_DOY</th>\n",
       "      <th>CONT_TIME</th>\n",
       "      <th>FIRE_SIZE</th>\n",
       "      <th>FIRE_SIZE_CLASS</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>OWNER_CODE</th>\n",
       "      <th>OWNER_DESCR</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1880465</td>\n",
       "      <td>1880465</td>\n",
       "      <td>1880465</td>\n",
       "      <td>923276</td>\n",
       "      <td>5183</td>\n",
       "      <td>1.880465e+06</td>\n",
       "      <td>1.880465e+06</td>\n",
       "      <td>1.880465e+06</td>\n",
       "      <td>997827</td>\n",
       "      <td>1.880465e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>988934.000000</td>\n",
       "      <td>908292</td>\n",
       "      <td>1.880465e+06</td>\n",
       "      <td>1880465</td>\n",
       "      <td>1.880465e+06</td>\n",
       "      <td>1.880465e+06</td>\n",
       "      <td>1.880465e+06</td>\n",
       "      <td>1880465</td>\n",
       "      <td>1880465</td>\n",
       "      <td>1202317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11</td>\n",
       "      <td>1640</td>\n",
       "      <td>1635</td>\n",
       "      <td>493633</td>\n",
       "      <td>1416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ST/C&amp;L</td>\n",
       "      <td>USGAGAS</td>\n",
       "      <td>Georgia Forestry Commission</td>\n",
       "      <td>GRASS FIRE</td>\n",
       "      <td>OSAGE-MIAMI COMPLEX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>CA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1377090</td>\n",
       "      <td>167123</td>\n",
       "      <td>167123</td>\n",
       "      <td>3983</td>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>939376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1050835</td>\n",
       "      <td>189550</td>\n",
       "      <td>7576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.003710e+03</td>\n",
       "      <td>2.453064e+06</td>\n",
       "      <td>1.647191e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.979037e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>172.656766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.452016e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.678121e+01</td>\n",
       "      <td>-9.570494e+01</td>\n",
       "      <td>1.059658e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.663099e+00</td>\n",
       "      <td>2.434573e+03</td>\n",
       "      <td>9.003891e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.483860e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>84.320348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.497598e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.139031e+00</td>\n",
       "      <td>1.671694e+01</td>\n",
       "      <td>4.404662e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.992000e+03</td>\n",
       "      <td>2.448622e+06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.793972e+01</td>\n",
       "      <td>-1.788026e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.998000e+03</td>\n",
       "      <td>2.451084e+06</td>\n",
       "      <td>8.900000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.281860e+01</td>\n",
       "      <td>-1.103635e+02</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.004000e+03</td>\n",
       "      <td>2.453178e+06</td>\n",
       "      <td>1.640000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.545250e+01</td>\n",
       "      <td>-9.204304e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>2.455036e+06</td>\n",
       "      <td>2.300000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.300000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.082720e+01</td>\n",
       "      <td>-8.229760e+01</td>\n",
       "      <td>1.400000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.015000e+03</td>\n",
       "      <td>2.457388e+06</td>\n",
       "      <td>3.660000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>366.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.069450e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.033060e+01</td>\n",
       "      <td>-6.525694e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       NWCG_REPORTING_AGENCY NWCG_REPORTING_UNIT_ID  \\\n",
       "count                1880465                1880465   \n",
       "unique                    11                   1640   \n",
       "top                   ST/C&L                USGAGAS   \n",
       "freq                 1377090                 167123   \n",
       "mean                     NaN                    NaN   \n",
       "std                      NaN                    NaN   \n",
       "min                      NaN                    NaN   \n",
       "25%                      NaN                    NaN   \n",
       "50%                      NaN                    NaN   \n",
       "75%                      NaN                    NaN   \n",
       "max                      NaN                    NaN   \n",
       "\n",
       "           NWCG_REPORTING_UNIT_NAME   FIRE_NAME         COMPLEX_NAME  \\\n",
       "count                       1880465      923276                 5183   \n",
       "unique                         1635      493633                 1416   \n",
       "top     Georgia Forestry Commission  GRASS FIRE  OSAGE-MIAMI COMPLEX   \n",
       "freq                         167123        3983                   54   \n",
       "mean                            NaN         NaN                  NaN   \n",
       "std                             NaN         NaN                  NaN   \n",
       "min                             NaN         NaN                  NaN   \n",
       "25%                             NaN         NaN                  NaN   \n",
       "50%                             NaN         NaN                  NaN   \n",
       "75%                             NaN         NaN                  NaN   \n",
       "max                             NaN         NaN                  NaN   \n",
       "\n",
       "           FIRE_YEAR  DISCOVERY_DATE  DISCOVERY_DOY DISCOVERY_TIME  \\\n",
       "count   1.880465e+06    1.880465e+06   1.880465e+06         997827   \n",
       "unique           NaN             NaN            NaN           1440   \n",
       "top              NaN             NaN            NaN           1400   \n",
       "freq             NaN             NaN            NaN          20981   \n",
       "mean    2.003710e+03    2.453064e+06   1.647191e+02            NaN   \n",
       "std     6.663099e+00    2.434573e+03   9.003891e+01            NaN   \n",
       "min     1.992000e+03    2.448622e+06   1.000000e+00            NaN   \n",
       "25%     1.998000e+03    2.451084e+06   8.900000e+01            NaN   \n",
       "50%     2.004000e+03    2.453178e+06   1.640000e+02            NaN   \n",
       "75%     2.009000e+03    2.455036e+06   2.300000e+02            NaN   \n",
       "max     2.015000e+03    2.457388e+06   3.660000e+02            NaN   \n",
       "\n",
       "        STAT_CAUSE_CODE   ...          CONT_DOY  CONT_TIME     FIRE_SIZE  \\\n",
       "count      1.880465e+06   ...     988934.000000     908292  1.880465e+06   \n",
       "unique              NaN   ...               NaN       1441           NaN   \n",
       "top                 NaN   ...               NaN       1800           NaN   \n",
       "freq                NaN   ...               NaN      38078           NaN   \n",
       "mean       5.979037e+00   ...        172.656766        NaN  7.452016e+01   \n",
       "std        3.483860e+00   ...         84.320348        NaN  2.497598e+03   \n",
       "min        1.000000e+00   ...          1.000000        NaN  1.000000e-05   \n",
       "25%        3.000000e+00   ...        102.000000        NaN  1.000000e-01   \n",
       "50%        5.000000e+00   ...        181.000000        NaN  1.000000e+00   \n",
       "75%        9.000000e+00   ...        232.000000        NaN  3.300000e+00   \n",
       "max        1.300000e+01   ...        366.000000        NaN  6.069450e+05   \n",
       "\n",
       "       FIRE_SIZE_CLASS      LATITUDE     LONGITUDE    OWNER_CODE  \\\n",
       "count          1880465  1.880465e+06  1.880465e+06  1.880465e+06   \n",
       "unique               7           NaN           NaN           NaN   \n",
       "top                  B           NaN           NaN           NaN   \n",
       "freq            939376           NaN           NaN           NaN   \n",
       "mean               NaN  3.678121e+01 -9.570494e+01  1.059658e+01   \n",
       "std                NaN  6.139031e+00  1.671694e+01  4.404662e+00   \n",
       "min                NaN  1.793972e+01 -1.788026e+02  0.000000e+00   \n",
       "25%                NaN  3.281860e+01 -1.103635e+02  8.000000e+00   \n",
       "50%                NaN  3.545250e+01 -9.204304e+01  1.400000e+01   \n",
       "75%                NaN  4.082720e+01 -8.229760e+01  1.400000e+01   \n",
       "max                NaN  7.033060e+01 -6.525694e+01  1.500000e+01   \n",
       "\n",
       "                  OWNER_DESCR    STATE   COUNTY  \n",
       "count                 1880465  1880465  1202317  \n",
       "unique                     16       52     3455  \n",
       "top     MISSING/NOT SPECIFIED       CA        5  \n",
       "freq                  1050835   189550     7576  \n",
       "mean                      NaN      NaN      NaN  \n",
       "std                       NaN      NaN      NaN  \n",
       "min                       NaN      NaN      NaN  \n",
       "25%                       NaN      NaN      NaN  \n",
       "50%                       NaN      NaN      NaN  \n",
       "75%                       NaN      NaN      NaN  \n",
       "max                       NaN      NaN      NaN  \n",
       "\n",
       "[11 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some initial observations about the data:\n",
    "- **STAT_CAUSE_CODE** and **STAT_CAUSE_DESCR** are related and represent the value that we are trying to predict. Before training, we'll drop **STAT_CAUSE_DESCR** in favor of the numerical value of **STAT_CAUSE_CODE**.\n",
    "- **OWNER_CODE** and **OWNER_DESCR** are related and describe the owner of the property where the fire was discovered. This is an interesting value because it represents the land management and usage of a particular peice of land. These will be interesting in our investigation. Before training, we'll drop **OWNER_DESCR** in favor of the numerical value of **OWNER_CODE**.\n",
    "- **DISCOVERY_DATE**, **DISCOVERY_DOY**, **DISCOVERY_TIME** describe the time that a fire was discovered. **DISCOVERY_DOY** is most interesting to our investigation due to it's relation to climate and usage patterns of a particular peice of land. **DISCOVERY_TIME** may be interesting due, but also might be too fine grained, additionally, it's missing values - let's drop it for now. **DISCOVERY_DATE** is [TKTK]\n",
    "- **LATITUDE**, and **LONGITUDE** are both very interesting due to their very high relationship to land cover, land use, and climate - all three big factors in wildfire creation.\n",
    "- **STATE** and  both categorically describe the location of a fire. **STATE** might be interesting due to it's relation in land use patterns. **STATE** also might prove to be a useful generalization of the more specific **LATITUDE**, and **LONGITUDE*.\n",
    "- **COUNTY**, while potentially interesting, has too many missing values. If we want to more closely explore categorial location data, we can add it via a geocoding process in the data engineering process.\n",
    "- A number of columns contain information about how a fire was addressed and not about what caused the fire. Lets' ignore the following columns for now: **NWCG_REPORTING_AGENCY**, **NWCG_REPORTING_UNIT_ID**, **NWCG_REPORTING_UNIT_NAME**, **FIRE_NAME**, **FIRE_COMPLEX**, **CONT_DATE**, **CONT_DOY**, **CONT_TIME**, **FIRE_SIZE**, **FIRE_SIZE_CLASS**\n",
    "\n",
    "This leaves us with the following interesting fields:\n",
    "- **STAT_CAUSE_CODE**\n",
    "- **STAT_CAUSE_DESCR** [for EDA]\n",
    "- **OWNER_CODE**\n",
    "- **OWNER_DESCR**\n",
    "- **DISCOVERY_DOY**\n",
    "- **LATITUDE**\n",
    "- **LONGITUDE**\n",
    "- **STATE**\n",
    "\n",
    "Some things we can keep in our back pocket for future exploration:\n",
    "- look harder at **DISCOVERY_TIME**\n",
    "- look harder at **DISCOVERY_DATE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Human Readable Mappings\n",
    "Before we drop our human readable columns, let's create a set of mappings that we can use to associate numberical categories back to human readable categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STAT_CAUSE_CODE\n",
       "1.0             Lightning\n",
       "2.0         Equipment Use\n",
       "3.0               Smoking\n",
       "4.0              Campfire\n",
       "5.0        Debris Burning\n",
       "6.0              Railroad\n",
       "7.0                 Arson\n",
       "8.0              Children\n",
       "9.0         Miscellaneous\n",
       "10.0            Fireworks\n",
       "11.0            Powerline\n",
       "12.0            Structure\n",
       "13.0    Missing/Undefined\n",
       "Name: STAT_CAUSE_DESCR, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_cause_mapping = raw_df \\\n",
    "    .groupby(['STAT_CAUSE_DESCR', 'STAT_CAUSE_CODE']) \\\n",
    "    .size()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .drop(0, axis=1)\\\n",
    "    .set_index('STAT_CAUSE_CODE')\\\n",
    "    .sort_index()['STAT_CAUSE_DESCR']\n",
    "stat_cause_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OWNER_CODE\n",
       "0.0                   FOREIGN\n",
       "1.0                       BLM\n",
       "2.0                       BIA\n",
       "3.0                       NPS\n",
       "4.0                       FWS\n",
       "5.0                      USFS\n",
       "6.0             OTHER FEDERAL\n",
       "7.0                     STATE\n",
       "8.0                   PRIVATE\n",
       "9.0                    TRIBAL\n",
       "10.0                      BOR\n",
       "11.0                   COUNTY\n",
       "12.0          MUNICIPAL/LOCAL\n",
       "13.0         STATE OR PRIVATE\n",
       "14.0    MISSING/NOT SPECIFIED\n",
       "15.0        UNDEFINED FEDERAL\n",
       "Name: OWNER_DESCR, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "owner_code_mapping = raw_df \\\n",
    "    .groupby(['OWNER_DESCR', 'OWNER_CODE']) \\\n",
    "    .size()\\\n",
    "    .to_frame()\\\n",
    "    .reset_index()\\\n",
    "    .drop(0, axis=1)\\\n",
    "    .set_index('OWNER_CODE')\\\n",
    "    .sort_index()['OWNER_DESCR']\n",
    "owner_code_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip Data\n",
    "\n",
    "Let's create a new dataframe that contains only the fields that we're interested in. This will reduce memory usage and help keep things tidy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1880465 entries, 0 to 1880464\n",
      "Data columns (total 8 columns):\n",
      "STAT_CAUSE_CODE     float64\n",
      "STAT_CAUSE_DESCR    object\n",
      "OWNER_CODE          float64\n",
      "OWNER_DESCR         object\n",
      "DISCOVERY_DOY       int64\n",
      "LATITUDE            float64\n",
      "LONGITUDE           float64\n",
      "STATE               object\n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 114.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df = raw_df.copy()[[\n",
    "    'STAT_CAUSE_CODE',\n",
    "    'STAT_CAUSE_DESCR',\n",
    "    'OWNER_CODE',\n",
    "    'OWNER_DESCR',\n",
    "    'DISCOVERY_DOY',\n",
    "    'LATITUDE',\n",
    "    'LONGITUDE',\n",
    "    'STATE'\n",
    "]]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint [0]\n",
    "\n",
    "Getting `gdf` to the state it is right now took some time. Let's checkpoint the file onto disk so we can come back to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_checkpoint_path = '../data/188-million-us-wildfires/wildfires-cause-prediction-df_checkpoint_0.pickle'\n",
    "\n",
    "# OVERWRITE = False\n",
    "\n",
    "# if not os.path.exists(df_checkpoint_path) or OVERWRITE:\n",
    "#     df.to_pickle(df_checkpoint_path)\n",
    "# else :\n",
    "#     df = pd.read_pickle(df_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data\n",
    "\n",
    "We need to split the data into a train set and a test set. The train set will be used to build our model, and the test set will be used to evaluate the model.\n",
    "\n",
    "We will use sklearn's [`model_selection.train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split our dataframe into two.\n",
    "\n",
    "Last, we will create a convienience `_df` that allows us to access the union of the test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p>\n",
       "    Number of Training Rows: 1410348<br />\n",
       "    Number of Test Rows: 470117\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = model_selection.train_test_split(df)\n",
    "\n",
    "display(HTML('''\n",
    "<p>\n",
    "    Number of Training Rows: {}<br />\n",
    "    Number of Test Rows: {}\n",
    "'''.format(train_df.shape[0], test_df.shape[0])))\n",
    "\n",
    "_df = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# END BLOG 1\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog Post 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "\n",
    "### Quantify Data\n",
    "\n",
    "A couple fields in our reduced set are still non-numeric, in particular the **STATE** field is still text - let's convert this to a numeric value.\n",
    "\n",
    "Ref: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = sklearn.preprocessing.LabelEncoder()\n",
    "for dataframe in _df:\n",
    "    dataframe['STATE_CODE'] = label.fit_transform(dataframe['STATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin Data\n",
    "\n",
    "Ref: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html  https://pandas.pydata.org/pandas-docs/stable/generated/pandas.qcut.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproject Data\n",
    "\n",
    "The latitude and longitude values in our input dataset are projected in the [NAD83 coordinate system](https://en.wikipedia.org/wiki/North_American_Datum). \n",
    "\n",
    "Ref: http://jswhit.github.io/pyproj/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data [0] - Exploratory Data Analysis\n",
    "\n",
    "1. Causes\n",
    "1. Week of Year [todo]\n",
    "1. Week of Year and Cause\n",
    "2. Owner\n",
    "3. Owner and Cause\n",
    "4. State\n",
    "5. State and Cause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causes\n",
    "\n",
    "Let's explore the causes of wildfires represented in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts_by_cause = test_df.groupby('STAT_CAUSE_DESCR')\\\n",
    "    .size()\\\n",
    "    .sort_values(ascending=False)\n",
    "counts_by_cause_pcts = counts_by_cause.apply(lambda x: 100 * x / float(counts_by_cause.sum()))\n",
    "\n",
    "ax = sns.barplot(counts_by_cause.index, counts_by_cause.values)\n",
    "ax.set_xticklabels(labels=counts_by_cause.index, rotation=90)\n",
    "\n",
    "for i, p in enumerate(ax.patches):\n",
    "    height = p.get_height()\n",
    "    width = p.get_width()\n",
    "    ax.text(\n",
    "        p.get_x()+(width/2.),\n",
    "        height + 1000,\n",
    "        '{:1.2f}%'.format(counts_by_cause_pcts[i]),\n",
    "        ha=\"center\") \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count_by_doy = train_df.groupby('DISCOVERY_DOY').size()\n",
    "ax = count_by_doy.plot()\n",
    "ax.set_xlim(0,367)\n",
    "ax.set_ylim(0,10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of Year and Cause\n",
    "\n",
    "Hypothesis: [TKTK]\n",
    "\n",
    "Process: Add 'DISCOVERY_WEEK' column to table. Note that we end up with 53 weeks as a result of Leap Years. I also added one to 1 index the list of weeks to better adhere with common understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process: Create a piviot table that relates `STAT_CAUSE_DESCR` to `DISCOVERY_WEEK`. Plot that using a seaborne heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cause_by_doy = train_df.groupby(['DISCOVERY_DOY', 'STAT_CAUSE_DESCR'])\\\n",
    "    .size()\\\n",
    "    .unstack()\n",
    "causes = list(cause_by_doy.columns.values)\n",
    "cause_by_doy['Total'] = cause_by_doy.sum(axis=1)\n",
    "cause_by_doy_proportional = pd.DataFrame()\n",
    "for cause in causes:\n",
    "    cause_by_doy_proportional[cause] = cause_by_doy[[cause, 'Total']].apply(lambda x: x[cause]/x['Total'], axis=1)\n",
    "cause_by_doy = cause_by_doy.drop('Total', axis=1)\n",
    "cause_by_doy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cycler import cycler\n",
    "ax = cause_by_doy.plot.area()\n",
    "ax.set_xlim(0,367)\n",
    "ax.set_ylim(0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(\n",
    "    cause_by_doy,\n",
    "    cbar_kws={'shrink':.9 },\n",
    "    annot=False,\n",
    "    cmap=quant_colormap.mpl_colormap\n",
    ")\n",
    "for i, label in enumerate(ax.yaxis.get_ticklabels()):\n",
    "    label.set_visible(False)\n",
    "    if i % 7 == 0:\n",
    "        label.set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(\n",
    "    cause_by_doy_proportional,\n",
    "    cbar_kws={'shrink':.9 }, \n",
    "    annot=False,\n",
    "    cmap=quant_colormap.mpl_colormap\n",
    ")\n",
    "for i, label in enumerate(ax.yaxis.get_ticklabels()):\n",
    "    label.set_visible(False)\n",
    "    if i % 7 == 0:\n",
    "        label.set_visible(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis: [TKTK]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts_by_owner = train_df.groupby('OWNER_DESCR')\\\n",
    "    .size()\\\n",
    "    .sort_values(ascending=False)\n",
    "\n",
    "ax = sns.barplot(counts_by_owner.index, counts_by_owner.values)\n",
    "labels = ax.set_xticklabels(labels=counts_by_owner.index, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cause and Owner\n",
    "\n",
    "Add 'DISCOVERY_WEEK' column to table. Note that we end up with 53 weeks as a result of Leap Years. I also added one to 1 index the list of weeks to better adhere with common understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_by_week = train_df.groupby(['OWNER_DESCR', 'STAT_CAUSE_DESCR'])\\\n",
    "    .size()\\\n",
    "    .unstack()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    cause_by_week,\n",
    "    cbar_kws={'shrink':.9 }, \n",
    "    annot=False,\n",
    "    cmap='inferno_r'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "counts_by_state = train_df.groupby('STATE')\\\n",
    "    .size()\\\n",
    "    .sort_values(ascending=False)\n",
    "\n",
    "ax = sns.barplot(counts_by_state.index, counts_by_state.values)\n",
    "labels = ax.set_xticklabels(labels=counts_by_state.index, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State, Geographic\n",
    "\n",
    "Load our State outlines, join in some abbreviations.\n",
    "\n",
    "Outlines sourced from: http://eric.clst.org/tech/usgeojson/\n",
    "\n",
    "#### Create States Dataframe containing Border Geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_outlines_path = '/data/188-million-us-wildfires/src/gz_2010_us_040_00_500k.json'\n",
    "state_outlines_df = gpd.read_file(state_outlines_path)\n",
    "\n",
    "state_codes_path = '/data/188-million-us-wildfires/src/state_codes.json'\n",
    "state_codes_df = pd.read_json(state_codes_path, orient='records').set_index('name')\n",
    "states = state_outlines_df\\\n",
    "    .join(state_codes_df, on='NAME').set_index('alpha-2')\\\n",
    "    .join(counts_by_state.to_frame().rename(columns={0:'count'}))\n",
    "states.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "states.to_crs({'init': 'epsg:3395'}).plot(column='count', cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State and Cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_by_state = train_df.groupby(['STATE', 'STAT_CAUSE_DESCR'])\\\n",
    "    .size()\\\n",
    "    .unstack()\n",
    "causes = list(cause_by_state.columns.values)\n",
    "cause_by_state['Total'] = cause_by_state.sum(axis=1)\n",
    "cause_by_state_proportional = pd.DataFrame()\n",
    "for cause in causes:\n",
    "    cause_by_state_proportional[cause] = cause_by_state[[cause, 'Total']].apply(lambda x: x[cause]/x['Total'], axis=1)\n",
    "cause_by_state = cause_by_state.drop('Total', axis=1)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    cause_by_state,\n",
    "    cbar_kws={'shrink':.9 }, \n",
    "    annot=False,\n",
    "    cmap='inferno_r'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Coorelation\n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heatmap of dataset\n",
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    #colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    colormap = quant_colormap.mpl_colormap\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        square=True,\n",
    "        cmap = colormap,\n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,\n",
    "        vmax=1.0,\n",
    "        linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# END BLOG 2\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENGINEER LOCATION OBJECT\n",
    "\n",
    "# geometry = [shapely.geometry.Point(xy) for xy in zip(df.LONGITUDE, df.LATITUDE)]\n",
    "# df.drop(['LONGITUDE', 'LATITUDE'], axis=1, inplace=True)\n",
    "# crs = {'init': 'epsg:4269'}\n",
    "# gdf = gpd.GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "# del df\n",
    "# gdf = gdf.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "# print(gdf.info())\n",
    "# gdf.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovery Week of Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in _df:\n",
    "    dataframe['DISCOVERY_WEEK'] = dataframe['DISCOVERY_DOY']\\\n",
    "        .apply(lambda x: math.floor(x/7) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Regions\n",
    "\n",
    "\n",
    "\n",
    "Ref: https://www.ncdc.noaa.gov/monitoring-references/maps/us-climate-regions.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLIMATE REGION\n",
    "climate_regions = {\n",
    "    \"northwest\": [\n",
    "        \"WA\",\n",
    "        \"OR\",\n",
    "        \"ID\"\n",
    "    ],\n",
    "    \"west\": [\n",
    "        \"CA\",\n",
    "        \"NV\",\n",
    "    ],\n",
    "    \"southwest\": [\n",
    "        \"UT\",\n",
    "        \"CO\",\n",
    "        \"AZ\",\n",
    "        \"NM\",\n",
    "    ],\n",
    "    \"northern_rockies\": [\n",
    "        \"MT\",\n",
    "        \"ND\",\n",
    "        \"SD\",\n",
    "        \"WY\",\n",
    "        \"NE\",\n",
    "    ],\n",
    "    \"upper_midwest\": [\n",
    "        \"KS\",\n",
    "        \"OK\",\n",
    "        \"TX\",\n",
    "        \"AR\",\n",
    "        \"LA\",\n",
    "        \"MS\",\n",
    "    ],\n",
    "    \"south\": [\n",
    "        \"MN\",\n",
    "        \"WI\",\n",
    "        \"MI\",\n",
    "        \"IA\"\n",
    "    ],\n",
    "    \"ohio_valley\": [\n",
    "        \"MO\",\n",
    "        \"IL\",\n",
    "        \"IN\",\n",
    "        \"OH\",\n",
    "        \"WV\",\n",
    "        \"KY\",\n",
    "        \"TN\",\n",
    "    ],\n",
    "    \"southeast\": [\n",
    "        \"VA\",\n",
    "        \"NC\",\n",
    "        \"SC\",\n",
    "        \"GA\",\n",
    "        \"AL\",\n",
    "        \"FL\",\n",
    "    ],\n",
    "    \"northeast\": [\n",
    "        \"ME\",\n",
    "        \"NH\",\n",
    "        \"VT\",\n",
    "        \"NY\",\n",
    "        \"PA\",\n",
    "        \"MA\",\n",
    "        \"RI\",\n",
    "        \"CT\",\n",
    "        \"NJ\",\n",
    "        \"DE\",\n",
    "        \"MD\",\n",
    "        \"DC\"\n",
    "    ],\n",
    "    \"alaska\": [\n",
    "        \"AK\",\n",
    "    ],\n",
    "    \"hawaii\": [\n",
    "        \"HI\"\n",
    "    ],\n",
    "    \"puerto_rico\": [\n",
    "        \"PR\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "state_region_mapping = {}\n",
    "for region, region_states in climate_regions.items():\n",
    "    for state in region_states:\n",
    "        state_region_mapping[state] = region\n",
    "        \n",
    "for dataframe in _df:\n",
    "    dataframe['CLIMATE_REGION'] = dataframe['STATE']\\\n",
    "        .apply(lambda x: state_region_mapping[x])\n",
    "        \n",
    "label = sklearn.preprocessing.LabelEncoder()\n",
    "for dataframe in _df:\n",
    "    dataframe['CLIMATE_REGION_CODE'] = label.fit_transform(dataframe['CLIMATE_REGION'])\n",
    "\n",
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H3 Binning\n",
    "\n",
    "Ref:\n",
    "\n",
    "https://github.com/uber/h3\n",
    "\n",
    "https://github.com/uber/h3/blob/master/docs/doxyfiles/restable.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "def h3_for_chunk(chunk, precision):\n",
    "    lat_lon_lines = \"\\n\".join([\"{} {}\".format(row['LATITUDE'], row['LONGITUDE']) for index,row in chunk.iterrows()])\n",
    "    h3 = subprocess.run(\n",
    "        ['/tools/h3/bin/geoToH3', str(precision)],\n",
    "        input=str.encode(lat_lon_lines),\n",
    "        stdout=subprocess.PIPE).stdout.decode('utf-8').splitlines()\n",
    "    return pd.DataFrame({\n",
    "        \"h3_{}\".format(precision): h3\n",
    "    }, index=chunk.index)\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "h3_df = pd.DataFrame()\n",
    "with tqdm(total=_df[0].shape[0]) as pbar:\n",
    "    for chunk in chunker(_df[0], 10000):\n",
    "        h3_df = pd.concat([h3_df, h3_for_chunk(chunk, 5)])\n",
    "        pbar.update(chunk.shape[0])\n",
    "_df[0] = _df[0].join(h3_df)\n",
    "\n",
    "h3_df = pd.DataFrame()\n",
    "with tqdm(total=_df[1].shape[1]) as pbar:\n",
    "    for chunk in chunker(_df[1], 10000):\n",
    "        h3_df = pd.concat([h3_df, h3_for_chunk(chunk, 5)])\n",
    "        pbar.update(chunk.shape[1])\n",
    "_df[1] = _df[1].join(h3_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>OWNER_CODE</th>\n",
       "      <th>OWNER_DESCR</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1250645</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Children</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>58</td>\n",
       "      <td>31.823900</td>\n",
       "      <td>-82.498100</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157543</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>USFS</td>\n",
       "      <td>207</td>\n",
       "      <td>37.345000</td>\n",
       "      <td>-106.972500</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1844989</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>7.0</td>\n",
       "      <td>STATE</td>\n",
       "      <td>164</td>\n",
       "      <td>45.729900</td>\n",
       "      <td>-122.362900</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216000</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BLM</td>\n",
       "      <td>254</td>\n",
       "      <td>34.650000</td>\n",
       "      <td>-117.234200</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673494</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>63</td>\n",
       "      <td>32.428800</td>\n",
       "      <td>-85.754428</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281668</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Arson</td>\n",
       "      <td>2.0</td>\n",
       "      <td>BIA</td>\n",
       "      <td>265</td>\n",
       "      <td>41.083200</td>\n",
       "      <td>-123.684500</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853418</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Missing/Undefined</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>76</td>\n",
       "      <td>32.194000</td>\n",
       "      <td>-110.834800</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822914</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Debris Burning</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>90</td>\n",
       "      <td>34.295269</td>\n",
       "      <td>-80.931343</td>\n",
       "      <td>SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501464</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Arson</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>115</td>\n",
       "      <td>45.792378</td>\n",
       "      <td>-93.433368</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339463</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>209</td>\n",
       "      <td>32.652930</td>\n",
       "      <td>-104.925540</td>\n",
       "      <td>NM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         STAT_CAUSE_CODE   STAT_CAUSE_DESCR  OWNER_CODE  \\\n",
       "1250645              8.0           Children         8.0   \n",
       "157543               1.0          Lightning         5.0   \n",
       "1844989              9.0      Miscellaneous         7.0   \n",
       "216000               9.0      Miscellaneous         1.0   \n",
       "1673494              9.0      Miscellaneous        14.0   \n",
       "281668               7.0              Arson         2.0   \n",
       "1853418             13.0  Missing/Undefined        14.0   \n",
       "1822914              5.0     Debris Burning         8.0   \n",
       "501464               7.0              Arson        14.0   \n",
       "339463               1.0          Lightning         8.0   \n",
       "\n",
       "                   OWNER_DESCR  DISCOVERY_DOY   LATITUDE   LONGITUDE STATE  \n",
       "1250645                PRIVATE             58  31.823900  -82.498100    GA  \n",
       "157543                    USFS            207  37.345000 -106.972500    CO  \n",
       "1844989                  STATE            164  45.729900 -122.362900    WA  \n",
       "216000                     BLM            254  34.650000 -117.234200    CA  \n",
       "1673494  MISSING/NOT SPECIFIED             63  32.428800  -85.754428    AL  \n",
       "281668                     BIA            265  41.083200 -123.684500    CA  \n",
       "1853418  MISSING/NOT SPECIFIED             76  32.194000 -110.834800    AZ  \n",
       "1822914                PRIVATE             90  34.295269  -80.931343    SC  \n",
       "501464   MISSING/NOT SPECIFIED            115  45.792378  -93.433368    MN  \n",
       "339463                 PRIVATE            209  32.652930 -104.925540    NM  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STAT_CAUSE_CODE</th>\n",
       "      <th>STAT_CAUSE_DESCR</th>\n",
       "      <th>OWNER_CODE</th>\n",
       "      <th>OWNER_DESCR</th>\n",
       "      <th>DISCOVERY_DOY</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>STATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1305567</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Equipment Use</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>323</td>\n",
       "      <td>43.059367</td>\n",
       "      <td>-108.361091</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320505</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Smoking</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>90</td>\n",
       "      <td>39.012455</td>\n",
       "      <td>-79.721108</td>\n",
       "      <td>WV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305735</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Campfire</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>118</td>\n",
       "      <td>42.766171</td>\n",
       "      <td>-108.797927</td>\n",
       "      <td>WY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276287</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Equipment Use</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PRIVATE</td>\n",
       "      <td>251</td>\n",
       "      <td>45.079250</td>\n",
       "      <td>-90.512730</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796473</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Arson</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>121</td>\n",
       "      <td>43.596278</td>\n",
       "      <td>-89.869891</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63249</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Lightning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>USFS</td>\n",
       "      <td>229</td>\n",
       "      <td>47.583333</td>\n",
       "      <td>-115.035000</td>\n",
       "      <td>MT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715850</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Children</td>\n",
       "      <td>12.0</td>\n",
       "      <td>MUNICIPAL/LOCAL</td>\n",
       "      <td>258</td>\n",
       "      <td>46.175750</td>\n",
       "      <td>-123.829080</td>\n",
       "      <td>OR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017609</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Equipment Use</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>117</td>\n",
       "      <td>35.658300</td>\n",
       "      <td>-81.421700</td>\n",
       "      <td>NC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Arson</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>68</td>\n",
       "      <td>30.644444</td>\n",
       "      <td>-89.135000</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983899</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>14.0</td>\n",
       "      <td>MISSING/NOT SPECIFIED</td>\n",
       "      <td>146</td>\n",
       "      <td>29.240000</td>\n",
       "      <td>-82.450000</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         STAT_CAUSE_CODE STAT_CAUSE_DESCR  OWNER_CODE            OWNER_DESCR  \\\n",
       "1305567              2.0    Equipment Use        14.0  MISSING/NOT SPECIFIED   \n",
       "1320505              3.0          Smoking         8.0                PRIVATE   \n",
       "1305735              4.0         Campfire        14.0  MISSING/NOT SPECIFIED   \n",
       "1276287              2.0    Equipment Use         8.0                PRIVATE   \n",
       "796473               7.0            Arson        14.0  MISSING/NOT SPECIFIED   \n",
       "63249                1.0        Lightning         5.0                   USFS   \n",
       "715850               8.0         Children        12.0        MUNICIPAL/LOCAL   \n",
       "1017609              2.0    Equipment Use        14.0  MISSING/NOT SPECIFIED   \n",
       "7476                 7.0            Arson        14.0  MISSING/NOT SPECIFIED   \n",
       "983899               9.0    Miscellaneous        14.0  MISSING/NOT SPECIFIED   \n",
       "\n",
       "         DISCOVERY_DOY   LATITUDE   LONGITUDE STATE  \n",
       "1305567            323  43.059367 -108.361091    WY  \n",
       "1320505             90  39.012455  -79.721108    WV  \n",
       "1305735            118  42.766171 -108.797927    WY  \n",
       "1276287            251  45.079250  -90.512730    WI  \n",
       "796473             121  43.596278  -89.869891    WI  \n",
       "63249              229  47.583333 -115.035000    MT  \n",
       "715850             258  46.175750 -123.829080    OR  \n",
       "1017609            117  35.658300  -81.421700    NC  \n",
       "7476                68  30.644444  -89.135000    MS  \n",
       "983899             146  29.240000  -82.450000    FL  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataframe in _df:\n",
    "    display(dataframe.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in _df:\n",
    "    display(dataframe.h3_5.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geohash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geohash\n",
    "\n",
    "def geohashes_for_geometry(geometry, precision=[7, 6, 4, 3]):\n",
    "    _lon = geometry.coords.xy[0][0]\n",
    "    _lat = geometry.coords.xy[1][0]\n",
    "    _geohash = geohash.encode(_lat, _lon, precision=precision[0])\n",
    "    _output = [_geohash[0:p] for p in precision]\n",
    "    return pd.Series(_output)\n",
    "\n",
    "\n",
    "for dataframe in _df:\n",
    "    geohashes = ['geometry'].apply(geohashes_for_geometry, precision=[4])\n",
    "geohashes = geohashes.rename(columns={0: 'geohash_5'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data [1]\n",
    "\n",
    "Now that we have engineered some new data, let's revisit some of our exploratory techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_by_region = train_df.groupby(['CLIMATE_REGION', 'STAT_CAUSE_DESCR'])\\\n",
    "    .size()\\\n",
    "    .unstack()\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    cause_by_region,\n",
    "    cbar_kws={'shrink':.9 }, \n",
    "    annot=False,\n",
    "    cmap='inferno_r'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Coorelation\n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heatmap of dataset\n",
    "def correlation_heatmap(df):\n",
    "    _ , ax = plt.subplots(figsize =(14, 12))\n",
    "    #colormap = sns.diverging_palette(220, 10, as_cmap = True)\n",
    "    colormap = quant_colormap.mpl_colormap\n",
    "    \n",
    "    _ = sns.heatmap(\n",
    "        df.corr(), \n",
    "        square=True,\n",
    "        cmap = colormap,\n",
    "        cbar_kws={'shrink':.9 }, \n",
    "        ax=ax,\n",
    "        annot=True, \n",
    "        linewidths=0.1,\n",
    "        vmax=1.0,\n",
    "        linecolor='white',\n",
    "        annot_kws={'fontsize':12 }\n",
    "    )\n",
    "    \n",
    "    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "\n",
    "correlation_heatmap(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop text category fields that duplicate numerical category fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_train_df = train_df.drop([\n",
    "#     'STAT_CAUSE_DESCR',\n",
    "#     'OWNER_DESCR',\n",
    "#     'STATE',\n",
    "#     'CLIMATE_REGION',\n",
    "# ], axis=1)\n",
    "# clean_train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Helper\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion Matrix',\n",
    "                          cmap=quant_colormap.mpl_colormap):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar(shrink=0.65)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh =  cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Actual label')\n",
    "    plt.ylabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Benchmark\n",
    "\n",
    "Before we train a model, let's establish a benchmark to work against. To do this, we will develop by hand, a very simple decision tree.\n",
    "\n",
    "The simplest benchmark that we can set is with a model that always evaluates to a single response. Our benchmark model will evaluate to `5.0`, the code representative of 'Debris Burning'.\n",
    "\n",
    "TODO: this benchmark should be improved once we have engineered some new data into our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_fields = [\n",
    "    'OWNER_CODE',\n",
    "    'DISCOVERY_WEEK',\n",
    "    'STATE_CODE'\n",
    "]\n",
    "\n",
    "target_fields = [\n",
    "    'STAT_CAUSE_CODE'\n",
    "]\n",
    "\n",
    "def benchmark_model(df):\n",
    "    return pd.DataFrame(data = {'STAT_CAUSE_CODE_PREDICT':[5.0 for i in range(0, df.shape[0])]})\n",
    "\n",
    "prediction = benchmark_model(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the accuracy of our benchmark model. It should fall right around 23% - this is the rough proportion of fires caused by 'Debris Burning'.\n",
    "\n",
    "Ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score  http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    ")\n",
    "\n",
    "print('Accuracy: {} \\n\\n'.format(accuracy))\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    "))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df[target_fields], prediction)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    stat_cause_mapping.values,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD) Classifier\n",
    "\n",
    "[TKTK]\n",
    "\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier\n",
    "\n",
    "http://scikit-learn.org/stable/modules/sgd.html#classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "source_fields = [\n",
    "    'OWNER_CODE',\n",
    "    'DISCOVERY_WEEK',\n",
    "    'STATE_CODE'\n",
    "]\n",
    "\n",
    "target_fields = [\n",
    "    'STAT_CAUSE_CODE'\n",
    "]\n",
    "\n",
    "classifier = SGDClassifier(\n",
    "    loss=\"hinge\",\n",
    "    penalty=\"l2\",\n",
    "    max_iter=5,\n",
    "    tol=None,\n",
    ")\n",
    "\n",
    "classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields]['STAT_CAUSE_CODE']\n",
    ")\n",
    "\n",
    "prediction = classifier.predict(\n",
    "    test_df[source_fields]\n",
    ")\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    ")\n",
    "\n",
    "print('Accuracy: {} \\n\\n'.format(accuracy))\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    "))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df[target_fields], prediction)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    stat_cause_mapping.values,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix'\n",
    ")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "source_fields = [\n",
    "    'OWNER_CODE',\n",
    "    'DISCOVERY_WEEK',\n",
    "    'STATE_CODE'\n",
    "]\n",
    "\n",
    "target_fields = [\n",
    "    'STAT_CAUSE_CODE'\n",
    "]\n",
    "\n",
    "classifier = DecisionTreeClassifier(\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields]\n",
    ")\n",
    "\n",
    "prediction = classifier.predict(\n",
    "    test_df[source_fields]\n",
    ")\n",
    "\n",
    "accuracy = sklearn.metrics.accuracy_score(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    ")\n",
    "\n",
    "print('Accuracy: {} \\n\\n'.format(accuracy))\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    test_df[target_fields],\n",
    "    prediction\n",
    "))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df[target_fields], prediction)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    stat_cause_mapping.values,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix'\n",
    ")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier Redux\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_fields = [\n",
    "    'OWNER_CODE',\n",
    "#     'DISCOVERY_WEEK',\n",
    "    'STATE_CODE'\n",
    "]\n",
    "\n",
    "target_fields = [\n",
    "    'STAT_CAUSE_CODE'\n",
    "]\n",
    "\n",
    "cv_split = sklearn.model_selection.ShuffleSplit(\n",
    "    n_splits=10,\n",
    "    test_size=0.3,\n",
    "    train_size=0.6,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classifier = DecisionTreeClassifier(\n",
    "    class_weight=None,\n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    presort=False,\n",
    "    random_state=0,\n",
    "    splitter='best'\n",
    ")\n",
    "\n",
    "base_results = model_selection.cross_validate(\n",
    "    base_classifier,\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields],\n",
    "    cv = cv_split\n",
    ")\n",
    "\n",
    "base_classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_classifier.tree_.node_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(base_classifier.get_params())\n",
    "print(\"Base Score: {}\".format(base_results['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = sklearn.tree.export_graphviz(\n",
    "    base_classifier,\n",
    "    out_file=None, \n",
    "    feature_names=source_fields,\n",
    "    class_names=True,\n",
    "    filled=True,\n",
    "    rounded = True\n",
    ")\n",
    "print(dot_data)\n",
    "graph = graphviz.Source(dot_data, engine='sfdp') \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Setup hyperparameter grid for decision tree. Using GridSearchCV, we will try various combinations of the parameters that we define.\n",
    "\n",
    "Ref:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"splitter\": [\"best\"],\n",
    "    \"max_depth\": [17, 19, 20, 22, 25],\n",
    "    \"min_samples_split\": [20, 40, 60],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],\n",
    "    \"min_weight_fraction_leaf\": [0],\n",
    "    \"max_features\": [None],\n",
    "    \"random_state\": [0],\n",
    "    \"max_leaf_nodes\": [None],\n",
    "    \"min_impurity_decrease\": [0.],\n",
    "    \"class_weight\": [None]\n",
    "}\n",
    "\n",
    "tuned_classifier = sklearn.model_selection.GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    hyperparameter_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=cv_split\n",
    ")\n",
    "\n",
    "tuned_classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(tuned_classifier.best_params_)\n",
    "print(\"Tuned Score: {}\".format(tuned_classifier.cv_results_['mean_test_score'][tuned_classifier.best_index_]))\n",
    "\n",
    "\n",
    "tuned_prediction = classifier.predict(\n",
    "    test_df[source_fields]\n",
    ")\n",
    "\n",
    "tuned_accuracy = sklearn.metrics.accuracy_score(\n",
    "    test_df[target_fields],\n",
    "    tuned_prediction\n",
    ")\n",
    "\n",
    "print('Accuracy: {} \\n\\n'.format(tuned_accuracy))\n",
    "\n",
    "print(sklearn.metrics.classification_report(\n",
    "    test_df[target_fields],\n",
    "    tuned_prediction\n",
    "))\n",
    "\n",
    "confusion_matrix = sklearn.metrics.confusion_matrix(test_df[target_fields], tuned_prediction)\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(\n",
    "    confusion_matrix,\n",
    "    stat_cause_mapping.values,\n",
    "    normalize=True,\n",
    "    title='Normalized confusion matrix'\n",
    ")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Elimination\n",
    "\n",
    "[TKTK]\n",
    "\n",
    "Ref:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_classifier = sklearn.feature_selection.RFECV(\n",
    "    base_classifier,\n",
    "    step=1,\n",
    "    scoring='accuracy',\n",
    "    cv=cv_split\n",
    ")\n",
    "\n",
    "rfe_classifier.fit(\n",
    "    train_df[source_fields],\n",
    "    train_df[target_fields]\n",
    ")\n",
    "\n",
    "rfe_support_columns = train_df[source_fields].columns.values[rfe_classifier.get_support()]\n",
    "\n",
    "rfe_results = model_selection.cross_validation(\n",
    "    base_classifier,\n",
    "    train_df[rfe_support_columns],\n",
    "    train_df[target_fields],\n",
    "    cv=cv_split\n",
    ")\n",
    "\n",
    "print(rfe_results)\n",
    "\n",
    "rfe_tuned_classifier = sklearn.model_selection.GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=0),\n",
    "    hyperparameter_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=cv_split\n",
    ")\n",
    "\n",
    "rfe_tuned_classifier.fit(\n",
    "    train_df[rfe_support_columns],\n",
    "    train_df[target_fields]\n",
    ")\n",
    "\n",
    "print(\"RFE + Tuned Score: {}\".format(rfe_tuned_classifier.cv_results_['mean_test_score'][classifier.best_index_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
